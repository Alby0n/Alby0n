{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alby0n/Alby0n/blob/main/Masked_facerecogntion_UI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#This is the USER INTERFACE"
      ],
      "metadata": {
        "id": "_opd1fK1m2y3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YtE-RbnGCa8w"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet gradio\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "\n",
        "def driverfunc(x,zipf,vid,y):\n",
        "  \n",
        "  resultimg,resultframe,resultmen,resultid=finalm(vid,zipf.name)\n",
        "  return [resultimg,resultframe,resultmen,resultid,\"Program Terminated\"]\n",
        "    \n",
        "\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=driverfunc,\n",
        "    inputs=[\n",
        "            gr.inputs.Textbox(lines=2,default=\"Upload The Zip Folder Containing the Images of People To Recognise Here\", label=\" \"),\n",
        "            gr.inputs.File(label=\"Zip Folder\"),\n",
        "            gr.inputs.Video(label=\"Upload the CCTV footage in here\"),\n",
        "            gr.inputs.Textbox(lines=2,default=\"Click Submit After Uploading the Files\", label=\" \")\n",
        "            \n",
        "            ],\n",
        "    outputs=[gr.outputs.Image(label=\"CCTV frame in which the person was detected\"),\n",
        "             gr.outputs.Image(label=\"Detected face of Person\"),\n",
        "             gr.outputs.Image(label=\"Photograph stored in Database\"),\n",
        "             \n",
        "             \n",
        "             gr.outputs.Textbox(type=\"number\"),\n",
        "             gr.outputs.Textbox(label=\"Message:\")],\n",
        "    title=\"FACE RECOGNITION SYSTEM\",\n",
        "    theme=\"darkhuggingface\",\n",
        "    #allow_screenshot=False,\n",
        "    allow_flagging=False,\n",
        "    #live=True\n",
        "     )\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmlZnRPCVOXN"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai1GDLh5C-KT",
        "outputId": "07707f33-ce62-4aa7-c2b3-b3bbbfc028c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZ0cXQ2833no"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.layers import Lambda, Flatten, Dense\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras import backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import PIL\n",
        "import cv2\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from tensorflow.keras.models import model_from_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mut9gytnQZmw",
        "outputId": "5bba041c-7f4b-4828-f99a-3e3ed0d1bd86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/1DH-h-EV6vCXF-KxnoBsD5kQYdu7a03PF/Create-Face-Data-from-Images-master\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "json_file = open('/content/gdrive/MyDrive/working models/model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "model = model_from_json(loaded_model_json)\n",
        "model.load_weights('/content/gdrive/MyDrive/working models/model.h5')\n",
        "FRmodel = model\n",
        "def img_to_encoding(image_path, model):\n",
        "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(160, 160))\n",
        "    \n",
        "    img = np.around(np.array(img) / 255.0, decimals=12)\n",
        "    x_train = np.expand_dims(img, axis=0)\n",
        "    embedding = model.predict_on_batch(x_train)\n",
        "    return embedding / np.linalg.norm(embedding, ord=2)\n",
        "\n",
        "database = {}\n",
        "#database[\"person 1\"] = img_to_encoding(\"/content/gdrive/MyDrive/dataset/manthan/generated/gen1.png\", FRmodel)\n",
        "#database[\"person 2\"] = img_to_encoding(\"/content/gdrive/MyDrive/dataset/manthan/generated/gen2.png\", FRmodel)\n",
        "#database[\"person 3\"] = img_to_encoding(\"/content/gdrive/MyDrive/dataset/manthan/generated/gen3.png\", FRmodel)\n",
        "#database[\"person 4\"] = img_to_encoding(\"/content/gdrive/MyDrive/dataset/manthan/generated/gen4.png\", FRmodel)\n",
        "#database[\"person 5\"] = img_to_encoding(\"/content/gdrive/MyDrive/dataset/manthan/generated/gen5.png\", FRmodel)\n",
        "\n",
        "\n",
        "def who_is_it(image_path, database, model):\n",
        "\n",
        "    encoding = img_to_encoding(image_path,model)\n",
        "\n",
        "    min_dist = 100\n",
        "\n",
        "    for (name, db_enc) in database.items():\n",
        "        \n",
        "        # Compute L2 distance between the target \"encoding\" and the current db_enc from the database. (≈ 1 line)\n",
        "        dist = np.linalg.norm(encoding - db_enc)\n",
        "\n",
        "        # If this distance is less than the min_dist, then set min_dist to dist, and identity to name. (≈ 3 lines)\n",
        "        if dist < min_dist:\n",
        "            min_dist = dist\n",
        "            identity = name\n",
        "    \n",
        "    # YOUR CODE ENDS HERE\n",
        "    \n",
        "    if min_dist > 1.2:\n",
        "        #print(\"Not in the database.\")\n",
        "        pass\n",
        "    else:\n",
        "      pass\n",
        "        #print (\"it's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
        "        #print (\"it's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
        "        \n",
        "    return min_dist, identity\n",
        "\n",
        "%cd /content/gdrive/MyDrive/dataset/manthan/Create-Face-Data-from-Images-master\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PR4ZKZ9a4wqo"
      },
      "outputs": [],
      "source": [
        "def most_common(List):\n",
        "    return(mode(List))\n",
        "\n",
        "def limitcnt(list5):\n",
        "  x=most_common(list5)\n",
        "  cnt = list5.count(x)\n",
        "  if cnt==8 and gflag==False:\n",
        "    flag=True\n",
        "    gflag=True\n",
        "def finalm(vid,zipfile): \n",
        "  \n",
        "  directory=\"/content/gdrive/MyDrive/dataset/manthan/generated/gen1\"\n",
        "  !unzip zipfile -d directory\n",
        "  \n",
        "  for filename in os.listdir(directory):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\") or filename.endswith(\".jpeg\"):\n",
        "        imz=os.path.join(directory, filename)\n",
        "        gi=img_to_encoding(imz,FRmodel)\n",
        "        database[filename] = gi\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "  \n",
        "  \n",
        " \n",
        "  cam = cv2.VideoCapture(vid) # video i/p\n",
        "  face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')  \n",
        "  try:\n",
        "      if not os.path.exists('images'):\n",
        "          os.makedirs('images')\n",
        "  except OSError:\n",
        "      print('Error: Creating directory of images')\n",
        "  currentframe = 0\n",
        "  while (True):\n",
        "      ret, frame = cam.read()\n",
        "      if ret:\n",
        "          name = './images/frame' + str(currentframe) + '.jpg'\n",
        "          print('Creating...' + name)\n",
        "          cv2.imwrite(name, frame)\n",
        "          currentframe += 1\n",
        "      else:\n",
        "          break\n",
        "  cam.release()\n",
        "  cv2.destroyAllWindows()\n",
        "\n",
        "  base_dir = os.path.dirname('!pwd')\n",
        "  prototxt_path = os.path.join(base_dir + 'model_data/deploy.prototxt')\n",
        "  caffemodel_path = os.path.join(base_dir + 'model_data/weights.caffemodel')\n",
        "\n",
        "  # Read the model\n",
        "  model = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
        "\n",
        "\n",
        "\n",
        "  # Create directory 'faces' if it does not exist\n",
        "  if not os.path.exists('faces'):\n",
        "      print(\"New directory created\")\n",
        "      os.makedirs('faces')\n",
        "\n",
        "  # Loop through all images and strip out faces\n",
        "  count = 0\n",
        "  Flg=False\n",
        "  list5=[]\n",
        "  flag=False\n",
        "  gflag=False\n",
        "  for file in os.listdir(base_dir + 'images'):\n",
        "      file_name, file_extension = os.path.splitext(file)\n",
        "      if (file_extension in ['.png','.jpg']):\n",
        "          \n",
        "          image = cv2.imread(base_dir + 'images/' + file)\n",
        "\n",
        "          (h, w) = image.shape[:2]\n",
        "          blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
        "\n",
        "          model.setInput(blob)\n",
        "          detections = model.forward()\n",
        "          try:\n",
        "          # Identify each face\n",
        "            for i in range(0, detections.shape[2]):\n",
        "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "                confidence = detections[0, 0, i, 2]\n",
        "\n",
        "              # If confidence > 0.5, save it as a separate file\n",
        "                if (confidence > 0.15):\n",
        "                    count += 1\n",
        "                    frame = image[startY:endY, startX:endX]\n",
        "                    cv2.imwrite(base_dir + 'faces/'   + \"aby.jpg\", frame)\n",
        "                  \n",
        "                    nope,id=who_is_it(base_dir + 'faces/'   + \"aby.jpg\", database, FRmodel)\n",
        "                    \n",
        "\n",
        "                    if(float(nope)<1.2):\n",
        "                      realMen=\"/content/gdrive/MyDrive/dataset/manthan/generated/gen1/\"+id\n",
        "                      realMen=cv2.imread(realMen)\n",
        "                      Flg=True\n",
        "                      return image,frame,realMen,id\n",
        "                      \n",
        "\n",
        "                      \n",
        "                 \n",
        "\n",
        "                      \n",
        "          except:\n",
        "            pass  \n",
        "  if Flg==False:\n",
        "    ss=\"None found in the database\"\n",
        "    fakeim=cv2.imread(\"/content/no.jpg\")\n",
        "    return fakeim,fakeim,fakeim,ss\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "szLkLCv25psl",
        "outputId": "b175cbe4-a01c-4854-dccc-6686ef8ac280"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-501cc14f09bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinalm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#working well\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: finalm() missing 2 required positional arguments: 'vid' and 'zipfile'"
          ]
        }
      ],
      "source": [
        "finalm()  #working well"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Masked facerecogntion UI.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}